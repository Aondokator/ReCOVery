{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Predicting News Reliablity Using News Content"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n  warnings.warn(message, FutureWarning)\n/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n  warnings.warn(message, FutureWarning)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import svm, naive_bayes, tree, ensemble, neighbors, linear_model\n",
    "from sklearn.inspection import permutation_importance\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "# from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix, f1_score, precision_score, recall_score\n",
    "import itertools\n",
    "from IPython.display import display\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "def plot_cm(cm, classes, path,\n",
    "                normalize=True,\n",
    "                cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    " \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    # plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.yticks(rotation=90, verticalalignment='center')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig(path, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "SMALL_SIZE = 16\n",
    "MEDIUM_SIZE = 18\n",
    "BIGGER_SIZE = 20\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE) \n",
    "\n",
    "CONTENT_FEATURE_PATH = \"feature/content-features.csv\"\n",
    "LABEL_PATH = \"feature/labels.csv\"\n",
    "CLASSES = ['is_unreliable', 'is_reliable']\n",
    "RSEED = 524"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def date_prep(fea_path, lab_path):\n",
    "    # Load data\n",
    "    fea_data = pd.read_csv(fea_path)  \n",
    "    lab_data = pd.read_csv(lab_path) \n",
    "    \n",
    "    features = pd.DataFrame(fea_data)  \n",
    "    labels = pd.DataFrame(lab_data)\n",
    "    \n",
    "    # Feature standardization\n",
    "    print(np.array(features)[:5,:5])\n",
    "    fea_scale = preprocessing.scale(features)\n",
    "    print(fea_scale[:5,:5])\n",
    "    \n",
    "    # Read feature names\n",
    "    fea_names = features.columns\n",
    "    print(fea_names[:5])\n",
    "    \n",
    "    # Divide the overall dataset as training data and testing data (0.8:0.2)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(fea_scale, labels, test_size=0.2, random_state=RSEED)\n",
    "\n",
    "    return fea_names, x_train, x_test, y_train, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Logistic Regression\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fea_names, x_train, x_test, y_train, y_test = date_prep(CONTENT_FEATURE_PATH, LABEL_PATH)\n",
    "\n",
    "model = linear_model.LogisticRegression(random_state=RSEED)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# perm = PermutationImportance(model, random_state=RSEED).fit(x_train, y_train)\n",
    "# display(eli5.show_weights(perm, feature_names = fea_names.tolist()))\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# cm_lg = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('=== Logistic Regression ===')\n",
    "print(classification_report(y_test, y_pred, target_names=CLASSES))\n",
    "# print(cm_lg)\n",
    "# plot_cm(cm_lg, classes,\n",
    "#         path = 'confusion matrix/cm_lg.eps',\n",
    "#         normalize=True,\n",
    "#         cmap=plt.cm.Blues)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Naive Bayes\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fea_names, x_train, x_test, y_train, y_test = date_prep(CONTENT_FEATURE_PATH, LABEL_PATH)\n",
    "\n",
    "'''\n",
    "Determining parameters:\n",
    "Cross validation based on grid search\n",
    "\n",
    "res = []\n",
    "for alpha in np.arange(0.1,1,0.1):\n",
    "    for binarize in np.arange(0,1,0.1):\n",
    "        model = naive_bayes.BernoulliNB(alpha=alpha, binarize=binarize)\n",
    "        cv_results = cross_val_score(model, x_train, y_train, scoring='f1', cv=10)\n",
    "        res.append([alpha, binarize, cv_results.mean()])\n",
    "bst_params = max(res, key=lambda re: re[-1])\n",
    "bst_alpha = bst_params[0]\n",
    "bst_binarize = bst_params[1]\n",
    "print('bst_params: [ %.1f, %.1f ]' %(bst_alpha,bst_binarize))\n",
    "'''\n",
    "\n",
    "bst_alpha = 0.1\n",
    "bst_binarize = 0\n",
    "model = naive_bayes.BernoulliNB(alpha=bst_alpha, binarize=bst_binarize)    \n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print('=== Naive Bayes ===')\n",
    "print(classification_report(y_test, y_pred, target_names=CLASSES))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "K-Nearest Neighbors\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fea_names, x_train, x_test, y_train, y_test = date_prep(CONTENT_FEATURE_PATH, LABEL_PATH)\n",
    "\n",
    "'''\n",
    "Determining parameters:\n",
    "Cross validation based on grid search\n",
    "\n",
    "res = []\n",
    "for n_neighbors in np.arange(1,10,1):\n",
    "    model = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    cv_results = cross_val_score(model, x_train, y_train, scoring='f1', cv=10)\n",
    "    res.append([n_neighbors, cv_results.mean()])\n",
    "bst_params = max(res, key=lambda re: re[-1])\n",
    "bst_n_neighbors = bst_params[0]\n",
    "print('bst_params: [ %.1f ]' %(bst_n_neighbors))\n",
    "'''\n",
    "\n",
    "bst_n_neighbors = 3\n",
    "model = neighbors.KNeighborsClassifier(n_neighbors=bst_n_neighbors)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print('=== KNN ===')\n",
    "print(classification_report(y_test, y_pred, target_names=CLASSES))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fea_names, x_train, x_test, y_train, y_test = date_prep(CONTENT_FEATURE_PATH, LABEL_PATH)\n",
    "\n",
    "'''\n",
    "Determining parameters:\n",
    "Cross validation based on grid search\n",
    "\n",
    "res = []\n",
    "for n_estimators in np.arange(100,500,100):\n",
    "    model = ensemble.RandomForestClassifier(n_estimators=n_estimators,random_state=RSEED)\n",
    "    cv_results = cross_val_score(model, x_train, y_train, scoring='f1', cv=10)\n",
    "    res.append([n_estimators, cv_results.mean()])\n",
    "bst_params = max(res, key=lambda re: re[-1])\n",
    "bst_n_estimators = bst_params[0]\n",
    "print('bst_params: [ %.1f ]' %(bst_n_estimators))\n",
    "'''\n",
    "\n",
    "bst_n_estimators = 300\n",
    "model = ensemble.RandomForestClassifier(n_estimators=bst_n_estimators)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "plt.figure(figsize=(5,6))\n",
    "plt.barh(range(len(indices)), importances[indices], color='steelblue', align='center')\n",
    "plt.yticks(range(len(indices)), [str(fea_names[i]) for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.savefig('figure/fea_imp_rf.eps',bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print('=== Random Forest ===')\n",
    "print(classification_report(y_test, y_pred, target_names=CLASSES))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Decision Tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fea_names, x_train, x_test, y_train, y_test = date_prep(CONTENT_FEATURE_PATH, LABEL_PATH)\n",
    "\n",
    "model = tree.DecisionTreeClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print('=== Decision Tree ===')\n",
    "print(classification_report(y_test, y_pred, target_names=CLASSES))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "SVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fea_names, x_train, x_test, y_train, y_test = date_prep(CONTENT_FEATURE_PATH, LABEL_PATH)\n",
    "\n",
    "kernel = 'rbf'\n",
    "max_iter = 2000\n",
    "model = svm.SVC(C=0.6, kernel=kernel, max_iter=max_iter, tol=0.01, random_state=RSEED)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "importances = permutation_importance(model, x_train, y_train)['importances_mean']\n",
    "indices = np.argsort(importances)\n",
    "plt.figure(figsize=(5,6))\n",
    "plt.barh(range(len(indices)), importances[indices], color='steelblue', align='center')\n",
    "plt.yticks(range(len(indices)), [str(fea_names[i]) for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.savefig('feature importance/fea_imp_svm.eps',bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print('=== SVM ===')\n",
    "print(classification_report(y_test, y_pred, target_names=CLASSES))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "XGBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fea_names, x_train, x_test, y_train, y_test = date_prep(CONTENT_FEATURE_PATH, LABEL_PATH)\n",
    "\n",
    "model = XGBClassifier(max_depth=5, subsample=0.6, reg_lambda=0.6, seed=RSEED)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "plt.figure(figsize=(5,6))\n",
    "plt.barh(range(len(indices)), importances[indices], color='steelblue', align='center')\n",
    "plt.yticks(range(len(indices)), [str(fea_names[i]) for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.savefig('figure/fea_imp_xgb.eps',bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print('=== XGBoost ===')\n",
    "print(classification_report(y_test, y_pred, target_names=CLASSES))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Performance of Random Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fea_names, x_train, x_test, y_train, y_test = date_prep(CONTENT_FEATURE_PATH, LABEL_PATH)\n",
    "\n",
    "model = DummyClassifier(strategy=\"uniform\")\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "cm_rand = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('=== Random ===')\n",
    "print(classification_report(y_test, y_pred, target_names=CLASSES))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}