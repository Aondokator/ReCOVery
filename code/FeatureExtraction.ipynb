{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Manually extract machine learning features based on content attributes\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import networkx\n",
    "import itertools\n",
    "\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mlt\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "load csv files\n",
    "    - combine all csv files as one df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# 0 is reliable\n",
    "# 1 is unreliable\n",
    "\n",
    "CSV_FILE_DIR_HEAD = \"/Volumes/MySSD/PycharmProjects/MIS-COV19/\"\n",
    "\n",
    "CSV_FILE_DIR0 = CSV_FILE_DIR_HEAD + \"dataset/reliable\"\n",
    "CSV_FILE_NAMES0 = os.listdir(CSV_FILE_DIR0)\n",
    "\n",
    "dfs0 = pd.DataFrame()\n",
    "for CSV_FILE_NAME in CSV_FILE_NAMES0:\n",
    "    if CSV_FILE_NAME[:12]==\"news-dataset\":\n",
    "        df = pd.read_csv(CSV_FILE_DIR0 + '/' + CSV_FILE_NAME) \n",
    "        dfs0 = pd.concat([dfs0,df])\n",
    "    dfs0 = dfs0[ ~dfs0['publish_date'].isin(['2010-07-06', '2020-07-24']) ]\n",
    "        \n",
    "dfs0['unreliability']='0'\n",
    "\n",
    "CSV_FILE_DIR1 = CSV_FILE_DIR_HEAD + \"dataset/unreliable\"\n",
    "CSV_FILE_NAMES1 = os.listdir(CSV_FILE_DIR1)\n",
    "\n",
    "dfs1 = pd.DataFrame()\n",
    "for CSV_FILE_NAME in CSV_FILE_NAMES1:\n",
    "    if CSV_FILE_NAME[:12]==\"news-dataset\":\n",
    "        df = pd.read_csv(CSV_FILE_DIR1 + '/' + CSV_FILE_NAME) \n",
    "        dfs1 = pd.concat([dfs1,df])\n",
    "    dfs1 = dfs1[ ~dfs1['publish_date'].isin(['2010-07-06', '2020-07-24']) ]\n",
    "        \n",
    "dfs1['unreliability']='1'\n",
    "\n",
    "dfs = pd.concat([dfs0,dfs1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Publisher ID"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "# Unique publishers: 55\n['FiveThirtyEight' 'FiveThirtyEight' 'The Mercury News' 'The Mercury News'\n 'The Mercury News']\n[17, 17, 44, 44, 44]\n[17 17 44 44 44]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "publishers = dfs['publisher'].values  \n",
    "\n",
    "pub_uni = np.unique(publishers)\n",
    "print(\"# Unique publishers: %d\" % pub_uni.shape[0])\n",
    "\n",
    "pub_dict = {}\n",
    "for idx in range(len(pub_uni)):\n",
    "    pub_dict[pub_uni[idx]] = idx + 1\n",
    "    \n",
    "print(publishers[:5])\n",
    "print([pub_dict[publishers[i]] for i in range(5)])\n",
    "\n",
    "fea_publisher = np.zeros(publishers.shape, dtype=int)\n",
    "for idx, pub in enumerate(publishers):\n",
    "    fea_publisher[idx] = pub_dict[pub]\n",
    "\n",
    "print(fea_publisher[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Publish year / month / day"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "['2020-05-15' '2020-04-22' '2020-05-18' '2020-03-04' '2020-05-18']\n[2020 2020 2020 2020 2020]\n[5 4 5 3 5]\n[15 22 18  4 18]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "dates = dfs['publish_date'].values\n",
    "dates = np.array(dates, dtype=str)\n",
    "\n",
    "fea_pub_yy = np.zeros(dates.shape, dtype=int)\n",
    "fea_pub_mm = np.zeros(dates.shape, dtype=int)\n",
    "fea_pub_dd = np.zeros(dates.shape, dtype=int)\n",
    "for idx, date in enumerate(dates):\n",
    "    if date == 'nan':\n",
    "        fea_pub_yy[idx], fea_pub_mm[idx], fea_pub_dd[idx] = 0, 0, 0\n",
    "    else:\n",
    "        fea_pub_yy[idx], fea_pub_mm[idx], fea_pub_dd[idx] = date.split('-')\n",
    " \n",
    "print(dates[:5])\n",
    "print(fea_pub_yy[:5])\n",
    "print(fea_pub_mm[:5])\n",
    "print(fea_pub_dd[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The number of authors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[\"['Dhrumil Mehta']\" \"['Likhitha Butchireddygari']\" \"['Lisa M. Krieger']\"\n \"['Alejandra Armstrong', 'Harriet Blair Rowan']\" \"['Paul Rogers']\"]\n[1 1 1 2 1]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "authors = dfs['author'].values\n",
    "authors = np.array(authors, dtype=str)\n",
    "fea_author_num = np.zeros(authors.shape, dtype=int)\n",
    "for idx, author in enumerate(authors):\n",
    "    if author == \"[]\":\n",
    "        fea_author_num[idx] = 0\n",
    "    else:\n",
    "        author_names = author[1:-1].split(',')\n",
    "        fea_author_num[idx] = len(author_names)\n",
    "\n",
    "print(authors[:5])\n",
    "print(fea_author_num[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The mean / median degree of authors in the co-author network"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "1095 ['Knvul Sheikh', 'Roni Caryn Rabin', 'Emily Feng', 'Nicole Wetsman', 'Zoe Schiffer', 'Jay Peters', 'Sean OKane', 'Kim Lyons', 'Elizabeth Lopatto', 'Josh Dzieza']\n1095 [3, 1, 1, 8, 8, 8, 8, 8, 10, 8]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "def get_list_authors(authors):\n",
    "    string_auth = authors[1:len(authors) - 1]\n",
    "    string_auth = string_auth.strip()\n",
    "    string_auth = string_auth.replace('\\'', '')\n",
    "    list_auth = string_auth.split(\", \")\n",
    "    return list_auth\n",
    "\n",
    "df = pd.read_csv(\"../dataset/recovery-news-data.csv\")\n",
    "authors = df['author'].dropna().unique()\n",
    "G=networkx.Graph()\n",
    "\n",
    "all_authors=[]\n",
    "count=0\n",
    "for author in authors:\n",
    "    all_authors.append(get_list_authors(author))\n",
    "del all_authors[3]\n",
    "\n",
    "authors_list = []\n",
    "list_auth_dict = []\n",
    "for author in all_authors:\n",
    "    num_auth_dict = {}\n",
    "    for each_author in author:\n",
    "        each_author = each_author.strip()\n",
    "        if each_author not in authors_list:\n",
    "            authors_list.append(each_author)\n",
    "            count+=1\n",
    "            num_auth_dict[count] = each_author\n",
    "        else:\n",
    "            num_auth_dict[authors_list.index(each_author)+1] = each_author\n",
    "    list_auth_dict.append(num_auth_dict)\n",
    " \n",
    "for authors1 in list_auth_dict:\n",
    "    keys_array = []\n",
    "    for key in authors1.keys():\n",
    "        keys_array.append(key)\n",
    "        G.add_node(key)\n",
    "    #print(keys_array)\n",
    "\n",
    "    if len(authors1) > 1:\n",
    "        pairs = list(itertools.combinations(keys_array, 2))\n",
    "        #print(pairs)\n",
    "        for pair in pairs:\n",
    "            G.add_edge(pair[0],pair[1])\n",
    "\n",
    "_, degrees = zip(*networkx.degree(G))\n",
    "degrees = list(degrees)\n",
    "\n",
    "print(len(authors_list), authors_list[:10])\n",
    "print(len(degrees), degrees[:10])\n",
    "\n",
    "authors = df['author'].values\n",
    "\n",
    "fea_deg_avg = np.zeros(authors.shape, dtype=float)\n",
    "fea_deg_med = np.zeros(authors.shape, dtype=int)\n",
    "\n",
    "for idx, author in enumerate(authors):\n",
    "    if author == \"[]\" or np.array(author, dtype=str) == 'nan':\n",
    "        fea_deg_avg[idx] = 0\n",
    "        fea_deg_med[idx] = 0\n",
    "    else:\n",
    "        # print(idx, author)\n",
    "        author_names = get_list_authors(author)\n",
    "        degree_list = []\n",
    "        for auth_name in author_names:\n",
    "            degree_list.append(degrees[authors_list.index(auth_name)])\n",
    "        fea_deg_avg[idx] = np.mean(degree_list)\n",
    "        fea_deg_med[idx] = np.median(degree_list)\n",
    "\n",
    "# print(len(fea_deg_avg), fea_deg_avg[:100])\n",
    "# print(len(fea_deg_med), fea_deg_med[:100])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The number of words in a news title / body-text / overall"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[17 12 14 11  9]\n",
      "[1489 1124  866  305  492]\n[1506 1136  880  316  501]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "titles = dfs['title'].values\n",
    "titles = np.array(titles, dtype=str)\n",
    "fea_title_word_nums = np.zeros(titles.shape, dtype=int)\n",
    "for idx, title in enumerate(titles):\n",
    "    fea_title_word_nums[idx] = len(title.split(' '))\n",
    "print(fea_title_word_nums[:5])\n",
    "\n",
    "\n",
    "bodies = dfs['body_text'].values\n",
    "bodies = np.array(bodies, dtype=str)\n",
    "fea_body_word_nums = np.zeros(bodies.shape, dtype=int)\n",
    "for idx, body in enumerate(bodies):\n",
    "    fea_body_word_nums[idx] = len(body.split(' '))\n",
    "print(fea_body_word_nums[:5])\n",
    "\n",
    "\n",
    "fea_word_nums = fea_title_word_nums + fea_body_word_nums\n",
    "print(fea_word_nums[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Have head/main/top image?\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "['https://fivethirtyeight.com/wp-content/uploads/2020/05/0515_POLLA-16x9-1.png?w=575'\n 'https://fivethirtyeight.com/wp-content/uploads/2020/04/AP_1203290115592-16x9-1.jpg?w=575'\n 'https://www.mercurynews.com/wp-content/uploads/2020/03/browning2.jpeg?w=1024&h=683'\n 'https://www.mercurynews.com/wp-content/uploads/2020/03/Bay-Area-covid-19-map.png?w=1024&h=576'\n 'https://www.mercurynews.com/wp-content/uploads/2020/04/SJM-L-BEACHCLOSED-0XXX-2b.jpg?w=1024&h=679']\n[1 1 1 1 1]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "images = dfs['image'].values\n",
    "images = np.array(images, dtype=str)\n",
    "fea_image_nums = np.zeros(images.shape, dtype=int)\n",
    "for idx, image in enumerate(images):\n",
    "    if image == 'nan':\n",
    "        fea_image_nums[idx] = 0\n",
    "    else:\n",
    "        fea_image_nums[idx] = 1\n",
    "\n",
    "print(images[:5])\n",
    "print(fea_image_nums[:5])    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Political Bias ID"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "# Unique political biases: 8\n['Center' 'Center' 'Left-center' 'Left-center' 'Left-center']\n[1, 1, 5, 5, 5]\n[1 1 5 5 5]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "biases = dfs['political_bias'].values  \n",
    "biases = np.array(biases, dtype=str)\n",
    "bias_uni = np.unique(biases)\n",
    "print(\"# Unique political biases: %d\" % bias_uni.shape[0])\n",
    "\n",
    "bias_dict = {}\n",
    "for idx in range(len(bias_uni)):\n",
    "    bias_dict[bias_uni[idx]] = idx + 1\n",
    "    \n",
    "print(biases[:5])\n",
    "print([bias_dict[biases[i]] for i in range(5)])\n",
    "\n",
    "fea_bias = np.zeros(biases.shape, dtype=int)\n",
    "for idx, bias in enumerate(biases):\n",
    "    fea_bias[idx] = bias_dict[bias]\n",
    "\n",
    "print(fea_bias[:5])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Country ID\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "# Unique countries: 7\n['USA' 'USA' 'USA' 'USA' 'USA']\n[6, 6, 6, 6, 6]\n[6 6 6 6 6]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "countries = dfs['country'].values  \n",
    "countries = np.array(countries, dtype=str)\n",
    "ctr_uni = np.unique(countries)\n",
    "print(\"# Unique countries: %d\" % ctr_uni.shape[0])\n",
    "\n",
    "ctr_dict = {}\n",
    "for idx in range(len(ctr_uni)):\n",
    "    ctr_dict[ctr_uni[idx]] = idx + 1\n",
    "    \n",
    "print(countries[:5])\n",
    "print([ctr_dict[countries[i]] for i in range(5)])\n",
    "\n",
    "fea_country = np.zeros(countries.shape, dtype=int)\n",
    "for idx, ctr in enumerate(countries):\n",
    "    fea_country[idx] = ctr_dict[ctr]\n",
    "\n",
    "print(fea_country[:5])   \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preparation for Unreliable News Prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "['0' '1']\n0    0\n1    0\n2    0\n3    0\n4    0\nName: is_unreliable, dtype: object\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "########## 1. construct the overall feature matrix ##########\n",
    "content_features = DataFrame({\n",
    "    # 'publisher': fea_publisher,\n",
    "    'publish_year': fea_pub_yy,\n",
    "    'publisher_month': fea_pub_mm,\n",
    "    'publisher_day': fea_pub_dd,\n",
    "    'author_num': fea_author_num,\n",
    "    'degree_avg': fea_deg_avg,\n",
    "    'degree_med': fea_deg_med,\n",
    "    'title_word_num': fea_title_word_nums,\n",
    "    'body_word_num': fea_body_word_nums,\n",
    "    'word_num': fea_word_nums,\n",
    "    'image_num': fea_image_nums,\n",
    "    # 'bias': fea_bias,\n",
    "    # 'country': fea_country\n",
    "    })\n",
    "\n",
    "########## 2. construct ground-truth label matrix ##########\n",
    "is_unreliable = dfs['unreliability'].values\n",
    "print(np.unique(is_unreliable))\n",
    "\n",
    "labels = DataFrame({ 'is_unreliable': is_unreliable })\n",
    "print(labels['is_unreliable'][:5])\n",
    "\n",
    "# Save features and labels to csv files\n",
    "content_features.to_csv(CSV_FILE_DIR_HEAD+'feature/content-features.csv', index=False)\n",
    "labels.to_csv(CSV_FILE_DIR_HEAD+'feature/labels.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}