{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Predicting News Reliablity Using All Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import svm, naive_bayes, tree, ensemble, neighbors, linear_model\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "CONTENT_FEATURE_PATH = \"../feature/content-features.csv\"\n",
    "SOCIAL_FEATURE_PATH = \"../feature/social-features.csv\"\n",
    "LABEL_PATH = \"../feature/labels.csv\"\n",
    "CLASSES = ['is_reliable', 'is_unreliable']\n",
    "RSEED = 46"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def date_prep(fea_path1, fea_path2, lab_path):\n",
    "    # Load data\n",
    "    fea_data1 = pd.read_csv(fea_path1)  \n",
    "    fea_data2 = pd.read_csv(fea_path2)  \n",
    "    lab_data = pd.read_csv(lab_path) \n",
    "    \n",
    "    features = np.array(np.hstack((fea_data1,fea_data2)))\n",
    "    labels = np.array(lab_data)\n",
    "    \n",
    "    # Feature standardization\n",
    "    fea_scale = preprocessing.scale(features)\n",
    "    \n",
    "    # Divide the overall dataset as training data and testing data (0.8:0.2)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(fea_scale, labels, test_size=0.2, random_state=RSEED)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Logistic Regression\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "=== Logistic Regression ===\n               precision    recall  f1-score   support\n\n  is_reliable       0.79      0.84      0.82       269\nis_unreliable       0.64      0.55      0.60       137\n\n     accuracy                           0.75       406\n    macro avg       0.72      0.70      0.71       406\n weighted avg       0.74      0.75      0.74       406\n\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:173: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n  warnings.warn(\"Numerical issues were encountered \"\n/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = date_prep(CONTENT_FEATURE_PATH, SOCIAL_FEATURE_PATH, LABEL_PATH)\n",
    "\n",
    "model = linear_model.LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print('=== Logistic Regression ===')\n",
    "print(classification_report(y_test, y_pred, target_names=CLASSES))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Naive Bayes\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "=== Naive Bayes ===\n               precision    recall  f1-score   support\n\n  is_reliable       0.81      0.75      0.78       269\nis_unreliable       0.57      0.65      0.61       137\n\n     accuracy                           0.72       406\n    macro avg       0.69      0.70      0.70       406\n weighted avg       0.73      0.72      0.72       406\n\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:173: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n  warnings.warn(\"Numerical issues were encountered \"\n/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = date_prep(CONTENT_FEATURE_PATH, SOCIAL_FEATURE_PATH, LABEL_PATH)\n",
    "\n",
    "model = naive_bayes.BernoulliNB() \n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print('=== Naive Bayes ===')\n",
    "print(classification_report(y_test, y_pred, target_names=CLASSES))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "K-Nearest Neighbors\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "=== KNN ===\n               precision    recall  f1-score   support\n\n  is_reliable       0.84      0.86      0.85       269\nis_unreliable       0.71      0.69      0.70       137\n\n     accuracy                           0.80       406\n    macro avg       0.77      0.77      0.77       406\n weighted avg       0.80      0.80      0.80       406\n\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:173: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n  warnings.warn(\"Numerical issues were encountered \"\n<ipython-input-48-0f0ab4dd6c6a>:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  model.fit(x_train, y_train)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = date_prep(CONTENT_FEATURE_PATH, SOCIAL_FEATURE_PATH, LABEL_PATH)\n",
    "\n",
    "model = neighbors.KNeighborsClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print('=== KNN ===')\n",
    "print(classification_report(y_test, y_pred, target_names=CLASSES))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:173: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n  warnings.warn(\"Numerical issues were encountered \"\n<ipython-input-49-384cd6515be5>:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  model.fit(x_train, y_train)\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "=== Random Forest ===\n               precision    recall  f1-score   support\n\n  is_reliable       0.89      0.93      0.91       269\nis_unreliable       0.85      0.77      0.80       137\n\n     accuracy                           0.87       406\n    macro avg       0.87      0.85      0.86       406\n weighted avg       0.87      0.87      0.87       406\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = date_prep(CONTENT_FEATURE_PATH, SOCIAL_FEATURE_PATH, LABEL_PATH)\n",
    "\n",
    "model = ensemble.RandomForestClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print('=== Random Forest ===')\n",
    "print(classification_report(y_test, y_pred, target_names=CLASSES))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Decision Tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "=== Decision Tree ===\n               precision    recall  f1-score   support\n\n  is_reliable       0.91      0.89      0.90       269\nis_unreliable       0.79      0.83      0.81       137\n\n     accuracy                           0.87       406\n    macro avg       0.85      0.86      0.86       406\n weighted avg       0.87      0.87      0.87       406\n\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:173: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n  warnings.warn(\"Numerical issues were encountered \"\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = date_prep(CONTENT_FEATURE_PATH, SOCIAL_FEATURE_PATH, LABEL_PATH)\n",
    "\n",
    "model = tree.DecisionTreeClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print('=== Decision Tree ===')\n",
    "print(classification_report(y_test, y_pred, target_names=CLASSES))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "SVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "=== SVM ===\n               precision    recall  f1-score   support\n\n  is_reliable       0.83      0.82      0.82       269\nis_unreliable       0.65      0.66      0.66       137\n\n     accuracy                           0.77       406\n    macro avg       0.74      0.74      0.74       406\n weighted avg       0.77      0.77      0.77       406\n\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:173: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n  warnings.warn(\"Numerical issues were encountered \"\n/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = date_prep(CONTENT_FEATURE_PATH, SOCIAL_FEATURE_PATH, LABEL_PATH)\n",
    "\n",
    "model = svm.SVC()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print('=== SVM ===')\n",
    "print(classification_report(y_test, y_pred, target_names=CLASSES))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "XGBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:173: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n  warnings.warn(\"Numerical issues were encountered \"\n/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "=== XGBoost ===\n               precision    recall  f1-score   support\n\n  is_reliable       0.89      0.93      0.91       269\nis_unreliable       0.86      0.78      0.82       137\n\n     accuracy                           0.88       406\n    macro avg       0.87      0.86      0.86       406\n weighted avg       0.88      0.88      0.88       406\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = date_prep(CONTENT_FEATURE_PATH, SOCIAL_FEATURE_PATH, LABEL_PATH)\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print('=== XGBoost ===')\n",
    "print(classification_report(y_test, y_pred, target_names=CLASSES))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Performance of Random Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "=== Random ===\n               precision    recall  f1-score   support\n\n  is_reliable       0.64      0.45      0.53       269\nis_unreliable       0.32      0.50      0.39       137\n\n     accuracy                           0.47       406\n    macro avg       0.48      0.47      0.46       406\n weighted avg       0.53      0.47      0.48       406\n\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:173: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n  warnings.warn(\"Numerical issues were encountered \"\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = date_prep(CONTENT_FEATURE_PATH, SOCIAL_FEATURE_PATH, LABEL_PATH)\n",
    "\n",
    "model = DummyClassifier(strategy=\"uniform\")\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print('=== Random ===')\n",
    "print(classification_report(y_test, y_pred, target_names=CLASSES))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}